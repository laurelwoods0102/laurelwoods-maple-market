{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.6 64-bit ('base': conda)",
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Source : https://github.com/A-bone1/FSNS-tfrecord-generate/blob/master/generate_tfrecord_PNG.py"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import numpy as np\n",
    "import glob\n",
    "import tensorflow\n",
    "from tensorflow.compat import v1 as tf\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "import PIL.Image as Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_utf8_string(text, length, null_char_id=0):\n",
    "    char_ids_padded = [null_char_id]*length\n",
    "    char_ids_unpadded = [null_char_id]*len(text)\n",
    "    for i in range(len(text)):\n",
    "        hash_id = ord(text[i])\n",
    "        char_ids_padded[i] = hash_id\n",
    "        char_ids_unpadded[i] = hash_id\n",
    "    return char_ids_padded, char_ids_unpadded\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1395\n"
    }
   ],
   "source": [
    "word_bag = {}\n",
    "with open('word_bag.txt', encoding=\"utf-8\") as dict_file:\n",
    "    for line in dict_file:\n",
    "        (key, value) = line.strip().split('\\t')\n",
    "        word_bag[value] = int(key)\n",
    "print(len(word_bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "29\n29\n"
    }
   ],
   "source": [
    "image_path = 'data/dataset_1/images/*.png'\n",
    "addrs_image = glob.glob(image_path)\n",
    "\n",
    "label_path = 'data/dataset_1/labels/*.txt'\n",
    "addrs_label = glob.glob(label_path)\n",
    "\n",
    "print(len(addrs_image))\n",
    "print(len(addrs_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "장비분류\\t:\\t눈장식\\n\nSTR\\t:\\t+24\\t(6\\t+18)\\n\nDEX\\t:\\t+33\\t(6\\t+27)\\n\nINT\\t:\\t+24\\t(6\\t+18)\\n\nLUK\\t:\\t+33\\t(6\\t+27)\\n\n공격력\\t:\\t+1\\n\n마력\\t:\\t+1\\n\n방어력\\t:\\t+100\\n\n업그레이드\\t가능\\t횟수:\\t3\\t(복구\\t가능\\t횟수:\\t0)\n"
    }
   ],
   "source": [
    "for text in open(addrs_label[j], encoding=\"utf-8\"):\n",
    "    #print(text.encode('unicode_escape'))\n",
    "    print(repr(text.replace(\" \", \"\\t\")).replace(\"'\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "장 51109\n비 48708\n분 48516\n류 47448\n  32\n: 58\n  32\n눈 45576\n장 51109\n식 49885\n\n 10\n"
    }
   ],
   "source": [
    "for text in open(addrs_label[j], encoding=\"utf-8\"):\n",
    "    for t in text:\n",
    "        print(t, ord(t))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train data: 0/29\n"
    }
   ],
   "source": [
    "tfrecord_writer  = tf.python_io.TFRecordWriter(\"tfexample_train\")\n",
    "\n",
    "#for j in range(0, int(len(addrs_image))): \n",
    "for j in range(0, 1): \n",
    "    print('Train data: {}/{}'.format(j,int(len(addrs_image))))\n",
    "    #sys.stdout.flush()\n",
    "\n",
    "    img = Image.open(addrs_image[j])\n",
    "\n",
    "    #img = img.resize((600, 150), Image.ANTIALIAS)\n",
    "    np_data = np.array(img)\n",
    "    image = tf.image.convert_image_dtype(np_data, dtype=tf.uint8)\n",
    "    encode_image = tf.image.encode_png(image).numpy()\n",
    "\n",
    "    '''\n",
    "    with tf.Session() as sess:\n",
    "        image_data = sess.run(tf.image.encode_png(image))\n",
    "        sess.close()\n",
    "    '''\n",
    "    for text in open(addrs_label[j], encoding=\"utf-8\"):\n",
    "        char_ids_padded, char_ids_unpadded = encode_utf8_string(\n",
    "            text=text,\n",
    "            length=400)\n",
    "\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(\n",
    "            feature={\n",
    "                'image/encoded': _bytes_feature(encode_image),\n",
    "                'image/format': _bytes_feature(b\"PNG\"),\n",
    "                'image/width': _int64_feature([np_data.shape[1]]),\n",
    "                'image/orig_width': _int64_feature([np_data.shape[1]]),\n",
    "                'image/class': _int64_feature(char_ids_padded),\n",
    "                'image/unpadded_class': _int64_feature(char_ids_unpadded),\n",
    "                'image/text': _bytes_feature(bytes(text, 'utf-8')),\n",
    "                # 'height': _int64_feature([crop_data.shape[0]]),\n",
    "            }\n",
    "        ))\n",
    "    tfrecord_writer.write(example.SerializeToString())\n",
    "\n",
    "#tfrecord_writer.close()\n",
    "#sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Readers are not supported when eager execution is enabled. Instead, please use tf.data to get data into your model.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m&lt;ipython-input-115-95070e9adc9e&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[1;34m\u001b[0m\n\u001b[1;32m----&gt; 1\u001b[1;33m \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFRecordReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m&quot;tfexample_train&quot;\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m&#39;in a future version&#39;\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m&#39;after %s&#39;\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--&gt; 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m&#39;deprecated&#39;\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\io_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, options)\u001b[0m\n\u001b[0;32m    449\u001b[0m     rr = gen_io_ops.tf_record_reader_v2(\n\u001b[0;32m    450\u001b[0m         name=name, compression_type=compression_type)\n\u001b[1;32m--&gt; 451\u001b[1;33m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTFRecordReader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\io_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, reader_ref, supports_serialize)\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m       raise RuntimeError(\n\u001b[1;32m--&gt; 133\u001b[1;33m           \u001b[1;34m&quot;Readers are not supported when eager execution is enabled. &quot;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m           &quot;Instead, please use tf.data to get data into your model.&quot;)\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Readers are not supported when eager execution is enabled. Instead, please use tf.data to get data into your model."
     ]
    }
   ],
   "source": [
    "reader = tf.TFRecordReader()\n",
    "_, ex = reader.read(\"tfexample_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "&#39;str&#39; object has no attribute &#39;queue_ref&#39;",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m&lt;ipython-input-116-44115d7d8508&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFRecordReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----&gt; 3\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m&quot;tfexample_train&quot;\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\io_ops.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, queue, name)\u001b[0m\n\u001b[0;32m    162\u001b[0m       \u001b[0mqueue_ref\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--&gt; 164\u001b[1;33m       \u001b[0mqueue_ref\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader_ref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresource\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgen_io_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader_read_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader_ref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueue_ref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: &#39;str&#39; object has no attribute &#39;queue_ref&#39;"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, ex = reader.read(\"tfexample_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}